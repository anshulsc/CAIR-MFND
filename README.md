# ğŸ›¡ï¸ FNDâ€” Agentic Fake News Detection Framework


**Author**: [Anshul Singh](https://anshulsc.github.io)

---

## Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [System Architecture](#system-architecture)
- [Technology Stack](#technology-stack)
- [Getting Started](#getting-started)
- [Deployment Modes](#deployment-modes)
- [Documentation](#documentation)
- [Directory Structure](#directory-structure)

---

## Overview

FND Mini is a sophisticated, multi-modal agentic framework for automated fake news detection. It combines:

- **Gemma 3 (12B)** via vLLM for multi-stage agentic reasoning
- **FraudNet** â€” a custom deep learning classifier for binary fake/true prediction
- **ChromaDB** vector search for evidence retrieval
- **LangGraph** to orchestrate agents in a stateful, debuggable graph
- **6 Indian fact-check scrapers** for live evidence collection
- **Brave Search API** for online evidence discovery

The entire pipeline is fully automated: submit a query (image + caption), and the system gathers evidence, runs multi-modal AI analysis, and generates a professional PDF report â€” all monitored through an interactive Streamlit dashboard with user authentication.

---

## Key Features

| Feature                      | Description                                                                                                                       |
| ---------------------------- | --------------------------------------------------------------------------------------------------------------------------------- |
| **Offline Query Mode**       | Submit image + caption queries; evidence is retrieved from a local ChromaDB vector database                                       |
| **Online Query Mode**        | The system searches the web via Brave Search API, downloads new evidence, indexes it, then runs the analysis                      |
| **Multi-Agent LLM Analysis** | Imageâ€“Text consistency, Imageâ€“Image similarity, Textâ€“Text factual alignment â€” all fused in a final reasoning stage                |
| **FraudNet Neural Network**  | A CLIP-based deep learning model that provides an independent fake/true classification with confidence scores                     |
| **Indian News Scrapers**     | 6 live scrapers (Factly, BoomLive, FactCrescendo, NewsChecker, NewsMobile, VishvasNews) to build and expand the evidence database |
| **PDF Report Generation**    | Professional, multi-page PDF reports with evidence, reasoning chains, and verdicts                                                |
| **User Authentication**      | Multi-user support with login/registration                                                                                        |
| **Highlight News Carousel**  | Dashboard carousel showcasing recently analyzed news stories                                                                      |
| **Trash & Restore**          | Soft-delete queries with the ability to restore or permanently delete                                                             |
| **Flexible Deployment**      | Local (offline), or publicly shared via Ngrok tunnels (online)                                                                    |

---

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STREAMLIT FRONTEND (Dashboard)                â”‚
â”‚                                                                 â”‚
â”‚  Dashboard â”€ Offline Query â”€ Online Query â”€ FraudNet â”€ Indian  â”‚
â”‚  Query Details â”€ FraudNet Details â”€ Trash â”€ Settings            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚  REST API calls
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FASTAPI BACKEND (API Server)                  â”‚
â”‚                                                                 â”‚
â”‚  Query CRUD â”€ Evidence Extraction â”€ Scraper Endpoints â”€ File    â”‚
â”‚  Serving â”€ Investigate & Analyze â”€ Data Explorer                â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚                       â”‚
       â–¼              â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Watcher   â”‚ â”‚ Main Worker â”‚ â”‚         Status Manager            â”‚
â”‚ (Watchdog) â”‚ â”‚ (Job Queue) â”‚ â”‚         (SQLite DB)               â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚
       â”‚              â”œâ”€â”€ Evidence Extraction (ChromaDB + CLIP)
       â”‚              â”œâ”€â”€ Model Inference (vLLM + LangGraph + FraudNet)
       â”‚              â””â”€â”€ PDF Generation (FPDF2)
       â”‚
       â””â”€â”€ Monitors 1_queries/ for new submissions
```

For a detailed architecture breakdown, see **[docs/ARCHITECTURE.md](docs/ARCHITECTURE.md)**.

---

## Technology Stack

| Layer                        | Technology                     |
| ---------------------------- | ------------------------------ |
| **Frontend**                 | Streamlit (multi-page app)     |
| **Backend API**              | FastAPI + Uvicorn              |
| **LLM Inference**            | vLLM with Gemma 3 (12B)        |
| **Agent Orchestration**      | LangGraph (StateGraph)         |
| **Neural Network**           | PyTorch (FraudNet classifier)  |
| **Feature Extraction**       | CLIP (ViT-L/14 via LAVIS)      |
| **Vector Database**          | ChromaDB                       |
| **Evidence Search (Online)** | Brave Search API               |
| **Web Scraping**             | BeautifulSoup4 / Requests      |
| **PDF Generation**           | FPDF2 + Markdown2              |
| **File Monitoring**          | Watchdog                       |
| **Authentication**           | Custom JSON-based user manager |
| **Tunnel/Sharing**           | Ngrok (pyngrok)                |

---

## Getting Started

### Prerequisites

- Python 3.10+
- NVIDIA GPU with CUDA (required for vLLM and FraudNet)
- A valid Brave Search API key (for online mode)
- `wget` (for downloading fonts)

### Quick Start

```bash
# 1. Clone and enter the project
git clone <your-repo-url>
cd FND_mini

# 2. Create and activate virtual environment
python3 -m venv .venv
source .venv/bin/activate

# 3. Install dependencies
pip install salesforce-lavis==1.0.2
pip install -r requirements.txt

# 4. Download fonts for PDF generation
mkdir -p assets/fonts
wget -P assets/fonts/ https://github.com/dejavu-fonts/dejavu-fonts/raw/master/ttf/DejaVuSans.ttf
wget -P assets/fonts/ https://github.com/dejavu-fonts/dejavu-fonts/raw/master/ttf/DejaVuSans-Bold.ttf

# 5. Populate the evidence database
# Place news article folders (each with image + caption.txt) into:
#   agentic_workspace/2_evidence_database/

# 6. Build the initial search index
python -m tools.build_index

# 7. Start the system
./start_system.sh
```

For detailed setup, deployment, and configuration instructions, see **[docs/SETUP.md](docs/SETUP.md)**.

---

## Deployment Modes

FND Mini supports **4 deployment configurations**:

| Script                       | Mode                   | Description                                                  |
| ---------------------------- | ---------------------- | ------------------------------------------------------------ |
| `start_system.sh`            | Local (all-in-one)     | Starts watcher, worker, API, and Streamlit frontend together |
| `deploy_backend_offline.sh`  | Backend only (local)   | Runs backend services on localhost without tunnels           |
| `deploy_backend.sh`          | Backend only (public)  | Runs backend + exposes API via Ngrok tunnel                  |
| `deploy_frontend_offline.sh` | Frontend only (local)  | Runs Streamlit connecting to localhost API                   |
| `deploy_frontend.sh`         | Frontend only (public) | Runs Streamlit + exposes UI via Ngrok tunnel                 |

**Typical remote deployment**: Run `deploy_backend.sh` on the GPU server, copy the Ngrok URL, then run `deploy_frontend.sh` on a separate machine with `API_URL` set to the backend's public URL.

For details, see **[docs/DEPLOYMENT.md](docs/DEPLOYMENT.md)**.

---

## Documentation

| Document                                  | Description                                                      |
| ----------------------------------------- | ---------------------------------------------------------------- |
| [ARCHITECTURE.md](docs/ARCHITECTURE.md)   | Detailed system architecture, component breakdown, and data flow |
| [WORKFLOW.md](docs/WORKFLOW.md)           | Step-by-step pipeline walkthrough (offline & online modes)       |
| [API_REFERENCE.md](docs/API_REFERENCE.md) | Complete REST API endpoint reference                             |
| [SETUP.md](docs/SETUP.md)                 | Installation, configuration, and deployment guide                |

---

## Directory Structure

```
FND_mini/
â”œâ”€â”€ Dashboard.py                # Main Streamlit dashboard (entry point)
â”œâ”€â”€ pages/                      # Streamlit multi-page app
â”‚   â”œâ”€â”€ 1_Offline Query Mode.py #   Submit query for offline analysis
â”‚   â”œâ”€â”€ 2_Query_Details.py      #   Detailed analysis results viewer
â”‚   â”œâ”€â”€ 3_Online Query Mode.py  #   Investigate & analyze with web search
â”‚   â”œâ”€â”€ 4_FraudNet.py           #   FraudNet prediction dashboard
â”‚   â”œâ”€â”€ 5_FraudNetDetails.py    #   Per-query FraudNet detail view
â”‚   â”œâ”€â”€ 6_Trash.py              #   Trash management (restore / delete)
â”‚   â”œâ”€â”€ 7_Settings.py           #   System settings & log viewer
â”‚   â””â”€â”€ 8_Indian Data.py        #   Indian news database + live scrapers
â”‚
â”œâ”€â”€ src/                        # Core Python source code
â”‚   â”œâ”€â”€ config.py               #   Central configuration (paths, model paths, API settings)
â”‚   â”œâ”€â”€ auth.py                 #   User authentication manager
â”‚   â”œâ”€â”€ workflow.py             #   LangGraph workflow definition
â”‚   â”œâ”€â”€ fraudnet.py             #   FraudNet model loading & inference
â”‚   â”œâ”€â”€ fraudnet_backbone.py    #   FraudNet neural network architecture
â”‚   â”œâ”€â”€ fraudnet_utils.py       #   CLIP feature extraction utilities
â”‚   â”œâ”€â”€ logger_config.py        #   Logging configuration
â”‚   â”œâ”€â”€ agents/                 #   AI agent module
â”‚   â”‚   â”œâ”€â”€ agent_class.py      #     MultimodalClaimVerifier (2-stage LLM pipeline)
â”‚   â”‚   â”œâ”€â”€ prompts.py          #     All LLM prompt templates
â”‚   â”‚   â””â”€â”€ utils.py            #     Model loading, batch inference, scoring utilities
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ main.py             #     FastAPI server with all REST endpoints
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â””â”€â”€ status_manager.py   #     SQLite-based query state tracking
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ evidence_searcher.py       # ChromaDB vector search (offline evidence)
â”‚   â”‚   â”œâ”€â”€ embedding_utils.py         # CLIP embedding generation
â”‚   â”‚   â”œâ”€â”€ online_evidence_extractor.py # Brave Search + download + index pipeline
â”‚   â”‚   â”œâ”€â”€ inference_pipeline.py      # Model initialization + LangGraph execution
â”‚   â”‚   â”œâ”€â”€ pdf_generator.py           # Professional PDF report renderer
â”‚   â”‚   â”œâ”€â”€ boomlive_scraper.py        # BoomLive fact-check scraper
â”‚   â”‚   â”œâ”€â”€ factly_scraper.py          # Factly.in scraper
â”‚   â”‚   â”œâ”€â”€ factcrescendo_scraper.py   # FactCrescendo scraper
â”‚   â”‚   â”œâ”€â”€ newschecker_sracper.py     # NewsChecker scraper
â”‚   â”‚   â”œâ”€â”€ newsmobile_scraper.py      # NewsMobile scraper
â”‚   â”‚   â””â”€â”€ vishwanews_scraper.py      # VishvasNews scraper
â”‚   â””â”€â”€ workers/
â”‚       â”œâ”€â”€ watcher.py          #     Monitors 1_queries/ for new submissions
â”‚       â””â”€â”€ main_worker.py      #     Job queue processor (evidence â†’ inference â†’ PDF)
â”‚
â”œâ”€â”€ tools/                      # Utility scripts
â”‚   â”œâ”€â”€ build_index.py          #   Build/rebuild ChromaDB vector index
â”‚   â””â”€â”€ add_query.py            #   CLI tool to add queries
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ backfill_verdicts.py    #   Backfill verdict column for existing queries
â”‚
â”œâ”€â”€ agentic_workspace/          # All runtime data
â”‚   â”œâ”€â”€ .system/                #   System internals (DB, logs, job queue, vector DB)
â”‚   â”œâ”€â”€ 1_queries/              #   Input: query folders (per-user subdirectories)
â”‚   â”œâ”€â”€ 2_evidence_database/    #   Input: evidence articles (image + caption.txt)
â”‚   â”œâ”€â”€ 3_processed_for_model/  #   Staging: prepared data for model inference
â”‚   â”œâ”€â”€ 4_results/              #   Output: generated PDF reports
â”‚   â”œâ”€â”€ 5_trash/                #   Soft-deleted queries
â”‚   â”œâ”€â”€ 6_fakeNewsData/         #   Scraped Indian fake news data
â”‚   â””â”€â”€ 7_highlight_news/       #   Curated highlight news for dashboard carousel
â”‚
â”œâ”€â”€ assets/fonts/               # DejaVu fonts for PDF generation
â”œâ”€â”€ logs/                       # Runtime logs (watcher, worker, API)
â”œâ”€â”€ docs/                       # Project documentation
â”‚
â”œâ”€â”€ start_system.sh             # All-in-one local launcher
â”œâ”€â”€ deploy_backend.sh           # Backend + Ngrok tunnel
â”œâ”€â”€ deploy_backend_offline.sh   # Backend (localhost only)
â”œâ”€â”€ deploy_frontend.sh          # Frontend + Ngrok tunnel
â”œâ”€â”€ deploy_frontend_offline.sh  # Frontend (localhost only)
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ tests/                      # Test suite
```
